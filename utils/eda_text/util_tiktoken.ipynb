{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "tiktoken は、OpenAI が開発した トークナイザー（tokenizer） のライブラリで、GPT系のモデル（たとえば gpt-3.5-turbo や gpt-4）が入力テキストを処理する際に、どのようにトークンに分割するかを決定するために使われます。\n",
    "URL(https://github.com/openai/tiktoken)\n",
    "\n",
    "# install\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "\n",
    "# よく使用される用途\n",
    "- チャット履歴のトークン数を計測して、モデルの制限内に収める\n",
    "- プロンプトの設計（token制限を意識）\n",
    "- コスト計算（OpenAIのAPIはトークン数に応じて課金）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textのトークン数を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通の用途"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"\n",
    "    指定したテキストのトークン数を計算する関数。\n",
    "\n",
    "    Args:\n",
    "        text (str): トークン数を数えたい文字列。\n",
    "        encoding_name (str): 使用するトークナイザの名前（デフォルト: \"cl100k_base\"）。これは、GPT-4, 3.5用\n",
    "\n",
    "    Returns:\n",
    "        int: テキストのトークン数。\n",
    "\n",
    "    使用例:\n",
    "        >>> count_tokens(\"Hello World!\")\n",
    "        3\n",
    "    \"\"\"\n",
    "    enc = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = enc.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "system_prompt = \"あなたは優秀なアシスタントです。AをBに変換してください。\"\n",
    "count_tokens(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高速化用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def get_encoding(encoding_name: str = \"o200k_base\") -> tiktoken.Encoding:\n",
    "    \"\"\"指定したエンコーディング名に基づいて、tiktokenのエンコーディングを取得する関数。\"\"\"\n",
    "    return tiktoken.get_encoding(encoding_name)\n",
    "\n",
    "def count_tokens(encoder: tiktoken.Encoding, text: str) -> int:\n",
    "    \"\"\"\n",
    "    指定したテキストのトークン数を計算する関数。\n",
    "    o200k_base: gpt-4o, gpt-4o-mini\n",
    "\n",
    "    Args:\n",
    "        encoder (tiktoken.Encoding): 使用するエンコーディング。\n",
    "        text (str): トークン数を数えたい文字列。\n",
    "\n",
    "    Returns:\n",
    "        int: テキストのトークン数。\n",
    "    Usage:\n",
    "        >>> encoder = get_encoding(\"o200k_base\")\n",
    "        >>> count_tokens(encoder, \"Hello World!\")\n",
    "        3\n",
    "    \"\"\"\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "system_prompt = \"あなたは優秀なアシスタントです。AをBに変換してください。\"\n",
    "encoder = get_encoding()\n",
    "count_tokens(encoder, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset内のtoken数の分布の可視化の実例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input: dataset class\n",
    "- output: token数の分布の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_tokens_wrapper(text, encoding_name=\"cl100k_base\"):\n",
    "    \"\"\"\n",
    "    子プロセスで実行するため、各テキストのトークン数を計算するラッパー関数。\n",
    "    プロセス毎にエンコーダを取得します。\n",
    "    \"\"\"\n",
    "    enc = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = enc.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# ds['train'] から article を取り出してリストにする\n",
    "texts = [item['article'] for item in ds['train']]\n",
    "\n",
    "N_CPUS = 10\n",
    "# ProcessPoolExecutor を使って並列処理を実行\n",
    "with ProcessPoolExecutor(max_workers=N_CPUS) as executor:\n",
    "    # executor.map は順序を保ったまま結果を返してくれるので、tqdm で進捗管理します\n",
    "    tokens_list = list(tqdm(executor.map(count_tokens_wrapper, texts), total=len(texts)))\n",
    "\n",
    "print(tokens_list[:10])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# tokens_list から中央値と最頻値を計算\n",
    "median_val = np.median(tokens_list)\n",
    "average_val = np.mean(tokens_list)\n",
    "max_val = np.max(tokens_list)\n",
    "min_val = np.min(tokens_list)\n",
    "print(f\"Median: {median_val}, Average: {average_val:.1f}, Max: {max_val}, Min: {min_val}\")\n",
    "\n",
    "# ヒストグラム描画\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(tokens_list, bins=100, kde=True)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# 中央値と最頻値の垂直線を追加\n",
    "plt.axvline(median_val, color='r', linestyle='--', linewidth=2, label=f'Median: {median_val}')\n",
    "plt.axvline(average_val, color='g', linestyle='-.', linewidth=2, label=f'Average: {average_val:.1f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
